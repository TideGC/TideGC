---
alias: Java 中字符串的长度
---

## Java 中字符串的长度

在 Java 中一个字符串的长度并「**不能**」简单地、想当然的想象成是其中所有字符数的累加和！

以下内容来自 stackoverflow 中的总结和解释

- A Java char takes always 16 bits. 
 
- A Unicode character, when encoded as UTF-16, takes “almost always” (not always) 16 bits: that’s because there are more than 64K unicode characters. Hence, a Java char is NOT a Unicode character (though “almost always” is). 

- “Almost always”, above, means the 64K first code points of Unicode, range 0x0000 to 0xFFF (BMP), which take 16 bits in the UTF-16 encoding. 

- A non-BMP (“rare”) Unicode character is represented as two Java chars (surrogate representation). This applies also to the literal representation as a string: For example, the character U+20000 is written as “\uD840\uDC00”. 

- Corolary: string.length() returns the number of java chars, not of Unicode chars. A string that has just one “rare” unicode character (eg U+20000) would return length() = 2 . Same consideration applies to any method that deals with char-sequences. 

- Java has little intelligence for dealing with non-BMP unicode characters as a whole. There are some utility methods that treat characters as code-points, represented as ints eg: Character.isLetter(int ch). Those are the real fully-Unicode methods.

``` java
String str1 = "\uD840\uDC00";
String str2 = "𠀀";

System.out.println(str2.length());
System.out.println(Character.isLetter(str2.charAt(0)));
```
