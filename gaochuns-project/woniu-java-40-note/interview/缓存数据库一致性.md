Redis 在我的项目中的一个使用场景就是作缓存。我的 xxx 功能中就是用了 Redis 作缓存。我会将根据 ID 查询的结果通过 spring-data-redis 的 Repository 存到 Redis 中。

## CAP

代码示例：[redis-cache-samples](https://github.com/hemiao3000/redis-cache-samples) 中的 sample-1-cap 。

对于 Redis 的缓存的操作，我们大体上采用的是 faceboo 的 Cache Aside Pattern 方案。就是：

- 在查询操作中，先查 Redis ，如果 Redis 中没有，就去查 MySQL 。查完 MySQL 之后<small>（ 在返回数据之前 ）</small>会把从 MySQL 查到的存到 Redis 中。
- 在修改和删除操作中，先操作 MySQL，执行修改和删除 SQL 语句，然后去 Redis 中删除这些变动的数据。

facebook 的 CAP 方案可以解决全部的"双写并发"问题，和绝大多数的读写并发问题。但是，有一种读写并发情况它解决不了：

| # | 描述 |
| :-: | :- |
|  1  | A 读 Redis（没有数据）|
|  2  | A 读 MySQL（读到旧数据）|
|  3  | B 改 MySQL（旧数据变新数据）|
|  4  | B 删 Redis（实际也没数据可删）|
|  5  | A 写 Redis（写入旧数据）|

如果有 2 个读写请求的线程，是以上面这种"时间线"交织到一起的，那么在执行完之后，Redis 中就是旧数据，MySQL 里面是新数据，再往后的别的读取操作就会一直从 Redis 中读到旧数据，而无视 MySQL 中的新数据。这就是可能会遇到的读写并发问题。

我们当时也分析过为什么 facebook 没有去处理这种情况，我们觉得因为大多数系统对数据的操作都是读多写少，在这种情况下，读写并发出问题是一个小概率事件，而且也并不是说只要出现读写并发就一定会出问题，例如，如果两个读写操作不是按我前面所说的"时间线"交织在一起，而是以下面这种方式交织：

| # | 描述 |
| :-: | :- |
|  1  | B 改 MySQL（旧数据变新数据）|
|  2  | A 读 Redis（没有数据）|
|  3  | A 读 MySQL（读到新数据）|
|  4  | A 写 Redis（写入新数据）|
|  5  | B 删 Redis（删除了新数据）|

如果 读写是这样并发、交织实际上也没有什么问题。所以，一方面读写并发的发生概率较小，另一方面读写并发又不是 100% 出问题，所以 facebook 的方案就没有去处理这种情况。

另外，即便是出现了读写并发导致的数据不一致问题，也不意味着这个"错误的缓存数据"会一直造成问题。因为，我们在写操作"存缓存"的操作中，存入数据库的数据时，会给它一个过期<small>（自动删除）</small>时间。所以，即便是出现了读写不一致的情况，实际上到缓存数据过期自动删除时，这个问题就自然而然的解决了。

> [!cite] 说辞一
> facebook 的 CAP 方案就是我们项目锁采用的解决 Redis 和缓存一致性的方案。对于 CAP 方案在高并发情况下有可能出现的读写并发问题，导致的数据不一致，我也有了解一些常见的解决方案，比如延迟删除。不过最终我们并没有用上。

> [!cite] 说辞二
> 不过，我们还是对 facebook 的方案做了改进，我们最终采用的是比较流行的另一种方案：延迟双删。

## 延迟双删

代码示例：[redis-cache-samples](https://github.com/hemiao3000/redis-cache-samples) 中的 sample-2-double-delete。

延迟双删方案对于 facebook 的 CAP 方案的最大的一点改进在于：它要求把执行修改、删除 SQL 语句之后的删除 Redis 的操作往后推迟。

在具体思想上，我们使用的是 "JDK 的线程池执行延迟任务" 的方式实现的延迟删除。

延迟删除之所以可以解决前面所说的读写并发问题是因为：通过延迟删除的方式，将写操作中的"删缓存"推迟到并发的读操作的"写"缓存之后：

| # | 描述 |
| :-: | :- |
|  1  | A 读 Redis（没有数据）|
|  2  | A 读 MySQL（读到旧数据）|
|  3  | B 改 MySQL（旧数据变新数据）|
|  4  | 延迟...     |
|  5  | A 写 Redis（写入旧数据）|
|  6  | 延迟...     |
|  7  | B 删 Redis（删除旧数据）|

这样一来，即便是读操作都到了旧数据，向 Redis 中写入旧数据，最终写操作的删除还是会删掉。这样就解决了读写并发问题。

当然，在实际的实现中，这里还是有个问题需要去考虑，就是这个延迟设置多长合适？为了确保写操作的 "删除 Redis" 一定要在读操作的 "存入 Redis" 之后，所以这个时长理论上来说越唱越保险。

我是这么分析这个问题的：

- 原始的 facebook 的 CAP 方案在没有出现读写并发问题时，它是没有 "缓存数据库数据不一致" 的时间窗口期的，如果出现了读写并发问题，那么它需要等 Redis 超时自动删除，在我们之前的方案中这个时间是 30 秒。

  所以，从统计和概率的角度来看的话，大多数情况下（大概率情况下），不一致窗口期时长为 0 ；极少部分情况下（小概率情况下），不一致窗口期时长为 30 秒；

- 延迟删除方案中，由于我们故意延迟 5 秒删除 Redis ，那么就等于说，无论是否出现读写并发问题，所有的写操作之后，100% 都会出现 5s 的数据不一致窗口期。

所以，为了避免这个 100% 的数据不一致窗口期，网上推荐的方案也好，我们自己最终采用的方案也好，都是要"双删"，就是删两次。

对于 "删两次" 这个操作，我自己在和同事讨论这个东西的时候有过一个纠结：为什么多出来的删 Redis 是要在更新 MySQL 之前，而不是在更新 MySQL 之后，因为我以前认为在更新 MySQL 之后先删一次 Redis ，再延迟删除一次 Redis ，即可以避免 "100% 数据不一致窗口期" 问题又可以避免"读写并发问题"，但是为什么要在更新 MysQL 之前删？

我自己是这么认为的：

如果是 "改数据库 - 删 Redis - 延迟删 Redis" 这样，如果 "删 Redis"<small>（ 第一次 ）</small>失败，那么需要回滚 MySQL 的操作；但是如果是 "删 Redis - 改数据库 - 延迟删 Redis" 这样，"删 Redis" 失败那么就直接返回，不用再执行 MySQL 操作了。

所以，提前 "第一次删 Redis" 提前到操作 MySQL 之前，是对 MySQL 的一种保护，有一种类似 "快速失败" 的效果。






